# Pulse Fetch MCP Server Configuration
# Copy this file to .env and fill in your actual values

# Docker Configuration (optional)
# The port for both host and container where the HTTP server will be accessible
PORT=3060

# ============================================================================
# HTTP SERVER CONFIGURATION (Remote Implementation Only)
# ============================================================================

# HTTP Server Port (optional)
# Port number for the HTTP server to listen on
# Only used in remote (HTTP transport) implementation
# Note: This is already set above in the Docker Configuration section
# Defaults to: 3060

# Node Environment (optional)
# Controls logging verbosity and security features
# Valid values: development, production, test
# - development: Verbose logging, DNS rebinding checks disabled
# - production: Minimal logging, DNS rebinding protection enabled
# - test: Test-specific logging
# NODE_ENV=production

# CORS Origins (optional)
# Comma-separated list of allowed origins for Cross-Origin Resource Sharing
# Only used in remote (HTTP transport) implementation
# Defaults to: * (allow all origins)
# Examples: https://app1.com,https://app2.com,http://localhost:3000
# ALLOWED_ORIGINS=*

# Allowed Hosts (optional)
# Comma-separated list of allowed host headers for DNS rebinding protection
# Only used in remote (HTTP transport) implementation with NODE_ENV=production
# IMPORTANT: Must include port if clients send Host header with port
# Examples: example.com,api.example.com:8080,localhost:3060
# ALLOWED_HOSTS=localhost:3060

# Session Resumability (optional)
# Enable session resumability using event store for HTTP streaming
# Only used in remote (HTTP transport) implementation
# Valid values: true, false
# Defaults to: false (resumability disabled)
# ENABLE_RESUMABILITY=true

# OAuth Authentication (optional)
# Enable OAuth authentication for the HTTP server
# Only used in remote (HTTP transport) implementation
# Valid values: true, false
# Defaults to: false (OAuth disabled)
# NOTE: OAuth is not yet implemented. When disabled (default), the /register and
# /authorize endpoints will return 404 with a clear error message. When enabled,
# they will return 501 (Not Implemented).
# ENABLE_OAUTH=false

# Metrics Authentication (optional)
# Enable authentication for metrics endpoints (/metrics, /metrics/json, /metrics/reset)
# Only used in remote (HTTP transport) implementation
# Recommended for production deployments to prevent unauthorized access
# Valid values: true, false
# Defaults to: false (no authentication required)
# When enabled, provide access via X-Metrics-Key header or ?key= query parameter
# Example: curl -H "X-Metrics-Key: secret" http://localhost:3060/metrics
# Example: curl http://localhost:3060/metrics?key=secret
# METRICS_AUTH_ENABLED=false
# METRICS_AUTH_KEY=your-secret-key-here

# ============================================================================
# DEVELOPMENT & DEBUGGING
# ============================================================================

# Debug Logging (optional)
# Enable debug-level logging regardless of NODE_ENV
# Set to any truthy value to enable
# DEBUG=true

# Log Format (optional)
# Controls the format of log output
# Valid values: text (default), json
# - text: Human-readable plain text logs with optional metadata
# - json: Structured JSON logs with timestamps for log aggregation
# Defaults to: text
# LOG_FORMAT=text

# Color Output Control (optional)
# Control ANSI color output in logs and console output
# NO_COLOR: Set to any value to disable all color output
# FORCE_COLOR: Set to '1' to force enable colors, '0' to force disable
# - NO_COLOR takes precedence over FORCE_COLOR
# - If neither set, colors enabled automatically when outputting to a TTY
# NO_COLOR=1
# FORCE_COLOR=1

# Skip Health Checks (optional)
# Skip API authentication health checks at startup
# Useful for self-hosted services without authentication or during development
# Valid values: true, false
# SKIP_HEALTH_CHECKS=false

# ============================================================================
# SCRAPING SERVICES
# ============================================================================

# Firecrawl API Key (optional)
# Get one at: https://www.firecrawl.dev/
FIRECRAWL_API_KEY=your-firecrawl-api-key-here

# Firecrawl API Base URL (optional)
# Custom base URL for Firecrawl API (useful for self-hosted instances)
# Defaults to: https://api.firecrawl.dev
# FIRECRAWL_BASE_URL=https://api.firecrawl.dev

# ============================================================================
# MAP TOOL CONFIGURATION
# ============================================================================

# Map Default Country (optional)
# ISO 3166-1 alpha-2 country code for map requests
# Determines proxy location and content localization
# Valid values: US, AU, DE, JP, GB, FR, CA, etc.
# Defaults to: US
# MAP_DEFAULT_COUNTRY=US

# Map Default Languages (optional)
# Comma-separated list of preferred languages for map requests
# Uses Accept-Language header format (language-region)
# Examples: en-US, en, en-US,es-ES, ja-JP
# Defaults to: en-US
# MAP_DEFAULT_LANGUAGES=en-US

# Map Max Results Per Page (optional)
# Maximum number of URLs to return per response
# Controls token usage: 200 URLs â‰ˆ 13k tokens (safe default under 15k limit)
# Valid range: 1-5000
# Defaults to: 200
# Examples:
#   100  - Ultra-efficient (~6.5k tokens)
#   200  - Balanced default (~13k tokens)
#   500  - More results per page (~32k tokens)
#   1000 - Large pages (~65k tokens, may exceed some LLM limits)
# MAP_MAX_RESULTS_PER_PAGE=200

# ============================================================================
# ADVANCED SCRAPING PARAMETERS REFERENCE (FIRECRAWL)
# ============================================================================
#
# The following parameters are available when using Firecrawl for scraping.
# These are configured per-request via MCP tool arguments, not environment variables.
# This section is provided as a reference for developers using the MCP tools.
#
# CACHE CONTROL:
# - maxAge: Accept cached results up to N milliseconds old (default: 172800000 = 2 days)
#   - Set to 0 for always-fresh results
#   - Firecrawl claims up to 500% speed improvement with caching enabled
#
# ANTI-BOT BYPASS:
# - proxy: Proxy type for anti-bot protection (default: "auto")
#   - "basic": Fast, standard proxy (1 credit per request)
#   - "stealth": Slow, advanced anti-bot bypass (5 credits per request)
#   - "auto": Smart retry - tries basic first, falls back to stealth on failure
#
# CONTENT FILTERING:
# - blockAds: Remove ads and cookie popups (default: true)
# - onlyMainContent: Extract only main content, exclude nav/footer (default: true)
# - includeTags: Array of CSS selectors to include (e.g., ["p", ".article"])
# - excludeTags: Array of CSS selectors to exclude (e.g., ["#ad", "nav"])
#
# OUTPUT FORMATS:
# - formats: Array of formats to extract (default: ["markdown", "html"])
#   - Available: markdown, html, rawHtml, links, images, screenshot, summary, branding
#
# BROWSER CONTROL:
# - waitFor: Milliseconds to wait before scraping (for JavaScript-heavy sites)
# - headers: Custom HTTP headers object (cookies, user-agent, authorization, etc.)
# - actions: Browser automation actions before scraping (click, scroll, type, etc.)
#
# CRAWL-SPECIFIC:
# - prompt: Natural language description of desired crawl behavior
#   - Example: "Find all blog posts about AI from the past year"
#   - Firecrawl automatically generates optimal crawl parameters from your description
#   - When provided, manual parameters may be overridden by AI-generated configuration
#
# BROWSER ACTIONS (for dynamic content):
# Available action types for automation before scraping:
# - wait: Pause for content to load { type: "wait", milliseconds: 2000 }
# - click: Click elements { type: "click", selector: "#load-more" }
# - write: Type into input fields { type: "write", selector: "#search", text: "query" }
# - press: Press keyboard keys { type: "press", key: "Enter" }
# - scroll: Scroll page { type: "scroll", direction: "down", amount: 500 }
# - screenshot: Capture page state { type: "screenshot", name: "after-login" }
# - scrape: Scrape specific element { type: "scrape", selector: "#content" }
# - executeJavascript: Run custom JS { type: "executeJavascript", script: "code here" }
#
# Example action sequence for login flow:
# [
#   { "type": "wait", "milliseconds": 1000 },
#   { "type": "click", "selector": "#cookie-accept" },
#   { "type": "write", "selector": "#email", "text": "user@example.com" },
#   { "type": "press", "key": "Enter" },
#   { "type": "wait", "milliseconds": 2000 },
#   { "type": "scrape", "selector": "#dashboard" }
# ]
#
# Note: These parameters are passed as arguments to MCP tool calls, not via environment
# variables. Configure them in your MCP client when calling scrape, crawl, or search tools.

# ============================================================================
# SCRAPING STRATEGY CONFIGURATION
# ============================================================================

# Strategy Configuration File Path (optional)
# Path to the markdown file containing scraping strategy configuration
# If not set, will use a default file in your OS temp directory
# Example: /path/to/your/scraping-strategies.md
# STRATEGY_CONFIG_PATH=/path/to/your/scraping-strategies.md

# Optimization Strategy (optional)
# Controls the order and selection of scraping strategies
# Valid values: cost (default), speed
# - cost: Tries native first, then firecrawl (optimizes for lowest cost)
# - speed: Tries firecrawl only (skips native for faster results)
#
# For self-hosted Firecrawl: Use "speed" for best results
# For detailed strategy selection guide: See docs/STRATEGY_SELECTION.md
# OPTIMIZE_FOR=cost

# ============================================================================
# RESOURCE STORAGE CONFIGURATION
# ============================================================================

# Resource Storage Configuration (optional)
# Controls how scraped resources are stored
# Valid values: memory (default), filesystem
# - memory: Stores resources in memory (lost on restart)
# - filesystem: Persists resources to disk
# MCP_RESOURCE_STORAGE=memory

# Filesystem Resource Storage Root (optional)
# Only used when MCP_RESOURCE_STORAGE=filesystem
# Directory where resources will be stored
# Defaults to: /tmp/pulse-crawl/resources (or OS equivalent)
# MCP_RESOURCE_FILESYSTEM_ROOT=/path/to/resource/storage

# Resource Cache TTL (optional)
# Time-to-live for cached resources in seconds
# After this time, resources are considered expired and will be evicted
# Set to 0 for infinite TTL (no expiration)
# Defaults to: 86400 (24 hours)
# MCP_RESOURCE_TTL=86400

# Resource Cache Max Size (optional)
# Maximum total size of cached resources in megabytes (MB)
# When exceeded, least recently used resources are evicted
# Defaults to: 100 (100 MB)
# MCP_RESOURCE_MAX_SIZE=100

# Resource Cache Max Items (optional)
# Maximum number of resources to keep in cache
# When exceeded, least recently used resources are evicted
# Defaults to: 1000
# MCP_RESOURCE_MAX_ITEMS=1000

# ============================================================================
# LLM PROVIDER CONFIGURATION (Extract Feature)
# ============================================================================

# LLM Provider Configuration (optional - for extract feature)
# Controls which LLM provider to use for intelligent content extraction
# This provides an alternative to MCP sampling for clients that don't support it
# Configure using the variables below for any LLM provider (Anthropic, OpenAI, or compatible)

# LLM Provider Type (optional)
# Valid values: anthropic, openai, openai-compatible
# - anthropic: Use Anthropic's Claude models directly
# - openai: Use OpenAI's GPT models
# - openai-compatible: Use any OpenAI-compatible provider (Together.ai, Groq, etc.)
# LLM_PROVIDER=anthropic

# LLM API Key (optional)
# The API key for your chosen LLM provider
# - For Anthropic: Get from https://console.anthropic.com/
# - For OpenAI: Get from https://platform.openai.com/
# - For others: Check your provider's documentation
# LLM_API_KEY=your-llm-api-key-here

# LLM API Base URL (optional)
# Only needed for openai-compatible providers
# Examples:
# - Together.ai: https://api.together.xyz/v1
# - Groq: https://api.groq.com/openai/v1
# - Perplexity: https://api.perplexity.ai
# LLM_API_BASE_URL=https://api.together.xyz/v1

# LLM Model (optional)
# The specific model to use for extraction
# Defaults:
# - Anthropic: claude-sonnet-4-20250514 (latest and most capable)
# - OpenAI: gpt-4.1-mini (latest and most capable)
# - OpenAI-compatible: Must be specified
# Examples:
# - Anthropic: claude-sonnet-4-20250514, claude-opus-4-20250514, claude-3-7-sonnet-20250219, claude-3-5-haiku-20241022
# - OpenAI: gpt-4.1-mini, gpt-4.1, gpt-4.1-nano, gpt-4o, gpt-4o-mini
# - Together.ai: meta-llama/Llama-3-70b-chat-hf
# LLM_MODEL=claude-sonnet-4-20250514
